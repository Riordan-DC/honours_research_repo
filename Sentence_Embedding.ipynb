{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "starting-european",
   "metadata": {},
   "source": [
    "# Sentence Embedding\n",
    "Riordan Callil 2021\n",
    "Honours research\n",
    "Developing an instruction understanding robot\n",
    "Current design: Instruction understanding using sentence embedding. Sentence embedding network will be trained in two phases. (1) Trained as a sentence autoencoder. Using the translation encoder-decoder framework. I will train the network to reconstruct the initial instruction from the latent representation. (2) I will fine tune the networks latent representations by training a classifier that uses the latent space to predict instruction action. (3) (FUTURE) As an additional step I might train the sentence autoencoder to translate high level instructions to low level instructions and visa versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-development",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "interracial-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-blake",
   "metadata": {},
   "source": [
    "# Dataset: ALFRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "turned-tunisia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6574/6574 [00:55<00:00, 118.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Loading and Transforming the ALFRED dataset utilites\n",
    "\n",
    "def load_next_alfred_data(ALFRED_JSON_PATTERN):\n",
    "    \"\"\"\n",
    "     Get list of all instructions and their trajectories\n",
    "     glob.glob gets all files and stores them. iglob makes an iterator.\n",
    "     \n",
    "    Paramaters:\n",
    "        @alfred_json_pattern\n",
    "        A string which represents the location of the data with glob style\n",
    "        regex expressions to denote multiple subdirectories.\n",
    "    \"\"\" \n",
    "    train_json_files = glob.glob(ALFRED_JSON_PATTERN)\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    wnl = WordNetLemmatizer()\n",
    "    dataset = []\n",
    "    \n",
    "    def preprocess_sentence(sentence):\n",
    "        sentence = tokenizer(sentence)\n",
    "        sentence = filter(lambda x: not x in string.punctuation, sentence)\n",
    "        sentence = [wnl.lemmatize(word) for word in sentence]\n",
    "        return sentence\n",
    "    \n",
    "    # Yeild an alfred json\n",
    "    for json_file_idx in tqdm.tqdm(range(len(train_json_files))):\n",
    "        data = json.load(open(train_json_files[json_file_idx]))\n",
    "        annotations = data['turk_annotations']['anns']\n",
    "        actions = data['plan']['high_pddl']\n",
    "        scene = data['scene']\n",
    "        scene['task_id'] = data['task_id']\n",
    "        \n",
    "        instruction_actions = []\n",
    "        for d in annotations:\n",
    "            votes = d['votes']\n",
    "            if all(votes): # WARNING: Limiting dataset based on votes\n",
    "                trajectory = {'task_desc': [], 'instructions': []}\n",
    "                trajectory['task_desc'] = preprocess_sentence(d['task_desc'])\n",
    "                for i in range(len(d['high_descs'])):\n",
    "                    sanitized_instruction = preprocess_sentence(d['high_descs'][i])\n",
    "                    #sanitized_instruction = tokenizer(d['high_descs'][i])\n",
    "                    #sanitized_instruction = filter(lambda x: not x in string.punctuation,sanitized_instruction)\n",
    "                    #sanitized_instruction = [wnl.lemmatize(word) for word in sanitized_instruction]\n",
    "                    instruction = {'instruction': sanitized_instruction, \n",
    "                                   'action': actions[i]['discrete_action']['action'],\n",
    "                                   'argument_1': actions[i]['discrete_action']['args'][0] if 0 < len(actions[i]['discrete_action']['args']) else '<unk>', \n",
    "                                   'argument_2': actions[i]['discrete_action']['args'][1] if 1 < len(actions[i]['discrete_action']['args']) else '<unk>'}\n",
    "                    trajectory['instructions'].append(instruction)\n",
    "                instruction_actions.append(trajectory)\n",
    "\n",
    "        if len(instruction_actions) > 0:\n",
    "            dataset.append((instruction_actions, scene))\n",
    "    return dataset\n",
    "\n",
    "dataset = load_next_alfred_data(\"D:/Datasets/alfred/data/ALFRED_json_2.1.0/train/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hairy-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 6568/6568 [00:00<00:00, 10057.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average sentence length = 11.13 words\n",
      "vocab size = 1932\n",
      "most common words:  [('the', 302611), ('to', 85218), ('turn', 63534), ('and', 58218), ('on', 49478), ('of', 49131), ('right', 38983), ('left', 37965), ('in', 32482), ('a', 29672)]\n",
      "most common actions:  [('GotoLocation', 60382), ('PickupObject', 27432), ('PutObject', 25331), ('CoolObject', 2660), ('SliceObject', 2645), ('HeatObject', 2605), ('CleanObject', 2500), ('ToggleObject', 2016), ('<SOS>', 1), ('<EOS>', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "class Language:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index: # Add word to langauge if unseen \n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def word(self, index):\n",
    "        return self.index2word.get(index)\n",
    "    \n",
    "    def index(self, word):\n",
    "        return self.word2index.get(word)\n",
    "    \n",
    "    def dump(self, filename):\n",
    "        obj = {\n",
    "            'word2index' : self.word2index,\n",
    "            'word2count' : self.word2count,\n",
    "            'index2word' : self.index2word,\n",
    "            'n_words' : self.n_words\n",
    "        }\n",
    "        with open(filename, 'w') as fp:\n",
    "            json.dump(obj, fp)\n",
    "    \n",
    "    def load(self, filename):\n",
    "        with open(filename, 'r') as fp:\n",
    "            obj = json.load(fp)\n",
    "            self.word2index = obj['word2index']\n",
    "            self.word2count = obj['word2count']\n",
    "            self.index2word = obj['index2word']\n",
    "            self.n_words = obj['n_words']\n",
    "    \n",
    "    def reset_counts(self):\n",
    "        self.word2count = dict.fromkeys(self.word2count, 0)\n",
    "\n",
    "# Check if backup, pickled, langauge object exists\n",
    "lang = Language()\n",
    "if os.path.isfile('instruction_language.json'):\n",
    "    lang.load('instruction_language.json')\n",
    "    lang.reset_counts()\n",
    "\n",
    "action_lang = Language()\n",
    "if os.path.isfile('action_language.json'):\n",
    "    action_lang.load('action_language.json')\n",
    "    action_lang.reset_counts()\n",
    "\n",
    "sentence_lengths = []\n",
    "lang.add_sentence([\"<SOS>\", \"<EOS>\"])\n",
    "action_lang.add_sentence([\"<SOS>\", \"<EOS>\"])\n",
    "# Add dataset to langauge object\n",
    "for task in tqdm.tqdm(dataset): \n",
    "    for trajectory in task[0]:\n",
    "        lang.add_sentence(trajectory['task_desc'])\n",
    "        sentence_lengths.append(len(trajectory['task_desc']))\n",
    "        for instruction in trajectory['instructions']:\n",
    "            instruction_text = instruction['instruction']\n",
    "            instruction_action = instruction['action']\n",
    "            instruction_arg_1 = instruction['argument_1']\n",
    "            instruction_arg_2 = instruction['argument_2']\n",
    "            if len(instruction_text) > 0:\n",
    "                lang.add_sentence(instruction_text)\n",
    "            action_lang.add_word(instruction_action)\n",
    "            if instruction_arg_1 != '<unk>':\n",
    "                lang.add_word(instruction_arg_1)\n",
    "            if instruction_arg_2 != '<unk>':\n",
    "                lang.add_word(instruction_arg_2)\n",
    "                \n",
    "            sentence_lengths.append(len(instruction_text))\n",
    "print('average sentence length = %.2f words' % (sum(sentence_lengths) / len(sentence_lengths)))\n",
    "\n",
    "# Pickle the language as a backup\n",
    "lang.dump('instruction_language.json')\n",
    "action_lang.dump('action_language.json')\n",
    "\n",
    "print('vocab size =', lang.n_words)\n",
    "print('most common words: ', sorted(lang.word2count.items(), key=lambda item: item[1], reverse=True)[:10])\n",
    "print('most common actions: ', sorted(action_lang.word2count.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "australian-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6568/6568 [00:01<00:00, 6178.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction samples = 144336\n",
      "high -> low pairs = 125571\n",
      "low -> action pairs = 125571\n",
      "low -> argument pairs = 125571\n",
      "using device: cuda\n",
      "sample = [['move', 'two', 'box', 'of', 'tissue', 'from', 'a', 'bathroom', 'counter', 'to', 'the', 'back', 'of', 'a', 'toilet'], ['turn', 'back', 'around', 'and', 'go', 'forward', 'to', 'the', 'toilet']]\n",
      "[['put', 'the', 'toilet', 'paper', 'on', 'top', 'of', 'the', 'toilet', 'tank', 'to', 'the', 'right', 'of', 'the', 'brown', 'roll'], ['PutObject']]\n",
      "(tensor([[269],\n",
      "        [  6],\n",
      "        [792],\n",
      "        [553],\n",
      "        [ 11],\n",
      "        [ 31],\n",
      "        [ 29],\n",
      "        [  6],\n",
      "        [792],\n",
      "        [793],\n",
      "        [ 27],\n",
      "        [  6],\n",
      "        [ 34],\n",
      "        [ 29],\n",
      "        [  6],\n",
      "        [ 82],\n",
      "        [817],\n",
      "        [  3]], device='cuda:0'), tensor([[7],\n",
      "        [3]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cirriculum:\n",
    "reconstruction = [] # [any text, any text]\n",
    "high_low_pairs = [] # [high level instruction, low level instruction] # Swap for variability\n",
    "low_action_pairs = [] # [low level instruction, action]\n",
    "low_argument_pairs = [] # [low level instructions, argument_1 argument_2]\n",
    "\n",
    "# Add dataset to langauge object\n",
    "for task in tqdm.tqdm(dataset):\n",
    "    for trajectory in task[0]:\n",
    "        reconstruction.append(trajectory['task_desc'])\n",
    "        for instruction in trajectory['instructions']:\n",
    "            instruction_text = instruction['instruction']\n",
    "            instruction_action = instruction['action']\n",
    "            instruction_arg_1 = instruction['argument_1']\n",
    "            instruction_arg_2 = instruction['argument_2']\n",
    "            instruction_args = []\n",
    "            if len(instruction_text) > 0:\n",
    "                reconstruction.append(instruction_text)\n",
    "                high_low_pairs.append([trajectory['task_desc'], instruction_text])\n",
    "                low_action_pairs.append([instruction_text, [instruction_action]])\n",
    "            if instruction_arg_1 != '<unk>':\n",
    "                if instruction_arg_1 == 'wineglass':\n",
    "                    print(instruction_text,instruction_arg_1 )\n",
    "                instruction_args.append(instruction_arg_1)\n",
    "            if instruction_arg_2 != '<unk>':\n",
    "                instruction_args.append(instruction_arg_2)\n",
    "            if len(instruction_args) > 0:\n",
    "                low_argument_pairs.append([instruction_text, instruction_args])\n",
    "\n",
    "print('reconstruction samples =', len(reconstruction))\n",
    "print('high -> low pairs =', len(high_low_pairs))\n",
    "print('low -> action pairs =', len(low_action_pairs))\n",
    "print('low -> argument pairs =', len(low_argument_pairs))\n",
    "\n",
    "import torch\n",
    "import random\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device: {}'.format(device))\n",
    "print('sample =', random.choice(high_low_pairs))\n",
    "\n",
    "# Prepare data for tensor representation\n",
    "def indices_from_sentence(lang, sentence):\n",
    "    return [lang.index(word) for word in sentence]\n",
    "\n",
    "def tensor_from_sentence(lang, sentence):\n",
    "    indices = indices_from_sentence(lang, sentence)\n",
    "    indices.append(lang.index('<EOS>'))\n",
    "    return torch.tensor(indices, dtype=torch.long, device=device).view(-1,1)\n",
    "\n",
    "def tensors_from_pair(input_lang, output_lang, pair):\n",
    "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
    "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "rpair = random.choice(low_action_pairs)\n",
    "print(rpair)\n",
    "print(tensors_from_pair(lang, action_lang, rpair))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-bathroom",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recreational-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# Sourced from Pytorch Tutorial: Seq2Seq Translation Tutorial\n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-galaxy",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "intellectual-stable",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updates:  54434\n",
      "0m 0s (- 8m 31s) (100 0%) 1.0726\n",
      "0m 1s (- 8m 29s) (200 0%) 0.5691\n",
      "0m 2s (- 8m 28s) (300 0%) 0.4351\n",
      "0m 3s (- 8m 25s) (400 0%) 0.3360\n",
      "0m 4s (- 8m 23s) (500 0%) 0.2484\n",
      "0m 5s (- 8m 21s) (600 1%) 0.1439\n",
      "0m 6s (- 8m 22s) (700 1%) 0.1152\n",
      "0m 7s (- 8m 23s) (800 1%) 0.0863\n",
      "0m 8s (- 8m 20s) (900 1%) 0.0604\n",
      "0m 9s (- 8m 18s) (1000 1%) 0.0519\n",
      "0m 10s (- 8m 17s) (1100 2%) 0.0698\n",
      "0m 11s (- 8m 15s) (1200 2%) 0.0492\n",
      "0m 12s (- 8m 15s) (1300 2%) 0.1044\n",
      "0m 13s (- 8m 15s) (1400 2%) 0.0424\n",
      "0m 14s (- 8m 14s) (1500 2%) 0.0131\n",
      "0m 14s (- 8m 12s) (1600 2%) 0.0245\n",
      "0m 15s (- 8m 11s) (1700 3%) 0.0594\n",
      "0m 16s (- 8m 9s) (1800 3%) 0.0079\n",
      "0m 17s (- 8m 7s) (1900 3%) 0.0293\n",
      "0m 18s (- 8m 6s) (2000 3%) 0.0766\n",
      "0m 19s (- 8m 4s) (2100 3%) 0.0059\n",
      "0m 20s (- 8m 3s) (2200 4%) 0.0050\n",
      "0m 21s (- 8m 2s) (2300 4%) 0.0306\n",
      "0m 22s (- 8m 1s) (2400 4%) 0.0331\n",
      "0m 23s (- 8m 1s) (2500 4%) 0.0030\n",
      "0m 24s (- 8m 0s) (2600 4%) 0.0178\n",
      "0m 25s (- 7m 59s) (2700 4%) 0.0209\n",
      "0m 25s (- 7m 57s) (2800 5%) 0.0055\n",
      "0m 26s (- 7m 56s) (2900 5%) 0.0129\n",
      "0m 27s (- 7m 54s) (3000 5%) 0.0643\n",
      "0m 28s (- 7m 52s) (3100 5%) 0.0193\n",
      "0m 29s (- 7m 52s) (3200 5%) 0.0190\n",
      "0m 30s (- 7m 51s) (3300 6%) 0.0025\n",
      "0m 31s (- 7m 51s) (3400 6%) 0.0040\n",
      "0m 32s (- 7m 50s) (3500 6%) 0.0091\n",
      "0m 33s (- 7m 49s) (3600 6%) 0.0322\n",
      "0m 34s (- 7m 48s) (3700 6%) 0.0131\n",
      "0m 35s (- 7m 47s) (3800 6%) 0.2048\n",
      "0m 36s (- 7m 47s) (3900 7%) 0.1428\n",
      "0m 36s (- 7m 46s) (4000 7%) 0.1577\n",
      "0m 37s (- 7m 46s) (4100 7%) 0.0693\n",
      "0m 38s (- 7m 45s) (4200 7%) 0.0495\n",
      "0m 39s (- 7m 45s) (4300 7%) 0.0270\n",
      "0m 40s (- 7m 44s) (4400 8%) 0.0160\n",
      "0m 41s (- 7m 44s) (4500 8%) 0.1727\n",
      "0m 42s (- 7m 43s) (4600 8%) 0.0420\n",
      "0m 43s (- 7m 43s) (4700 8%) 0.0601\n",
      "0m 44s (- 7m 42s) (4800 8%) 0.0292\n",
      "0m 45s (- 7m 42s) (4900 9%) 0.0254\n",
      "0m 46s (- 7m 41s) (5000 9%) 0.0505\n",
      "0m 47s (- 7m 40s) (5100 9%) 0.0416\n",
      "0m 48s (- 7m 39s) (5200 9%) 0.0144\n",
      "0m 49s (- 7m 38s) (5300 9%) 0.0393\n",
      "0m 50s (- 7m 38s) (5400 9%) 0.0961\n",
      "0m 51s (- 7m 37s) (5500 10%) 0.0239\n",
      "0m 52s (- 7m 36s) (5600 10%) 0.0379\n",
      "0m 53s (- 7m 35s) (5700 10%) 0.0736\n",
      "0m 54s (- 7m 34s) (5800 10%) 0.0070\n",
      "0m 55s (- 7m 33s) (5900 10%) 0.0112\n",
      "0m 56s (- 7m 32s) (6000 11%) 0.0093\n",
      "0m 57s (- 7m 32s) (6100 11%) 0.0213\n",
      "0m 58s (- 7m 31s) (6200 11%) 0.0316\n",
      "0m 59s (- 7m 31s) (6300 11%) 0.1093\n",
      "0m 59s (- 7m 30s) (6400 11%) 0.0131\n",
      "1m 0s (- 7m 29s) (6500 11%) 0.0229\n",
      "1m 1s (- 7m 28s) (6600 12%) 0.0358\n",
      "1m 2s (- 7m 27s) (6700 12%) 0.0030\n",
      "1m 3s (- 7m 26s) (6800 12%) 0.0506\n",
      "1m 4s (- 7m 25s) (6900 12%) 0.0446\n",
      "1m 5s (- 7m 24s) (7000 12%) 0.0037\n",
      "1m 6s (- 7m 23s) (7100 13%) 0.0042\n",
      "1m 7s (- 7m 23s) (7200 13%) 0.0178\n",
      "1m 8s (- 7m 22s) (7300 13%) 0.0133\n",
      "1m 9s (- 7m 21s) (7400 13%) 0.0034\n",
      "1m 10s (- 7m 20s) (7500 13%) 0.0132\n",
      "1m 11s (- 7m 20s) (7600 13%) 0.0100\n",
      "1m 12s (- 7m 19s) (7700 14%) 0.0014\n",
      "1m 13s (- 7m 18s) (7800 14%) 0.0951\n",
      "1m 14s (- 7m 17s) (7900 14%) 0.0583\n",
      "1m 15s (- 7m 16s) (8000 14%) 0.0040\n",
      "1m 16s (- 7m 16s) (8100 14%) 0.0059\n",
      "1m 17s (- 7m 14s) (8200 15%) 0.1476\n",
      "1m 18s (- 7m 14s) (8300 15%) 0.0095\n",
      "1m 19s (- 7m 13s) (8400 15%) 0.0645\n",
      "1m 20s (- 7m 12s) (8500 15%) 0.0364\n",
      "1m 21s (- 7m 11s) (8600 15%) 0.0350\n",
      "1m 22s (- 7m 11s) (8700 15%) 0.0663\n",
      "1m 22s (- 7m 10s) (8800 16%) 0.1003\n",
      "1m 23s (- 7m 9s) (8900 16%) 0.0477\n",
      "1m 24s (- 7m 8s) (9000 16%) 0.0554\n",
      "1m 25s (- 7m 7s) (9100 16%) 0.0394\n",
      "1m 26s (- 7m 6s) (9200 16%) 0.0568\n",
      "1m 27s (- 7m 5s) (9300 17%) 0.1448\n",
      "1m 28s (- 7m 5s) (9400 17%) 0.0053\n",
      "1m 29s (- 7m 4s) (9500 17%) 0.2877\n",
      "1m 30s (- 7m 3s) (9600 17%) 0.1701\n",
      "1m 31s (- 7m 2s) (9700 17%) 0.0487\n",
      "1m 32s (- 7m 1s) (9800 18%) 0.0077\n",
      "1m 33s (- 7m 0s) (9900 18%) 0.0127\n",
      "1m 34s (- 7m 0s) (10000 18%) 0.0044\n",
      "1m 35s (- 6m 59s) (10100 18%) 0.0247\n",
      "1m 36s (- 6m 58s) (10200 18%) 0.0051\n",
      "1m 37s (- 6m 57s) (10300 18%) 0.0034\n",
      "1m 38s (- 6m 57s) (10400 19%) 0.0027\n",
      "1m 39s (- 6m 56s) (10500 19%) 0.0026\n",
      "1m 40s (- 6m 56s) (10600 19%) 0.0028\n",
      "1m 41s (- 6m 55s) (10700 19%) 0.0016\n",
      "1m 42s (- 6m 54s) (10800 19%) 0.0013\n",
      "1m 43s (- 6m 54s) (10900 20%) 0.0026\n",
      "1m 44s (- 6m 53s) (11000 20%) 0.0674\n",
      "1m 45s (- 6m 53s) (11100 20%) 0.0063\n",
      "1m 46s (- 6m 52s) (11200 20%) 0.0013\n",
      "1m 47s (- 6m 51s) (11300 20%) 0.0046\n",
      "1m 48s (- 6m 50s) (11400 20%) 0.1346\n",
      "1m 49s (- 6m 49s) (11500 21%) 0.0305\n",
      "1m 50s (- 6m 49s) (11600 21%) 0.0045\n",
      "1m 51s (- 6m 48s) (11700 21%) 0.0134\n",
      "1m 52s (- 6m 47s) (11800 21%) 0.0129\n",
      "1m 53s (- 6m 47s) (11900 21%) 0.0175\n",
      "1m 54s (- 6m 46s) (12000 22%) 0.1893\n",
      "1m 55s (- 6m 45s) (12100 22%) 0.0624\n",
      "1m 56s (- 6m 44s) (12200 22%) 0.0036\n",
      "1m 57s (- 6m 43s) (12300 22%) 0.1401\n",
      "1m 58s (- 6m 42s) (12400 22%) 0.0440\n",
      "1m 59s (- 6m 41s) (12500 22%) 0.1265\n",
      "2m 0s (- 6m 40s) (12600 23%) 0.1426\n",
      "2m 1s (- 6m 40s) (12700 23%) 0.0168\n",
      "2m 2s (- 6m 39s) (12800 23%) 0.1535\n",
      "2m 3s (- 6m 38s) (12900 23%) 0.0506\n",
      "2m 4s (- 6m 37s) (13000 23%) 0.0089\n",
      "2m 5s (- 6m 36s) (13100 24%) 0.1509\n",
      "2m 6s (- 6m 35s) (13200 24%) 0.1008\n",
      "2m 7s (- 6m 34s) (13300 24%) 0.1012\n",
      "2m 8s (- 6m 34s) (13400 24%) 0.0660\n",
      "2m 9s (- 6m 33s) (13500 24%) 0.0322\n",
      "2m 10s (- 6m 32s) (13600 24%) 0.1364\n",
      "2m 11s (- 6m 31s) (13700 25%) 0.0681\n",
      "2m 12s (- 6m 30s) (13800 25%) 0.0910\n",
      "2m 13s (- 6m 29s) (13900 25%) 0.0082\n",
      "2m 14s (- 6m 28s) (14000 25%) 0.1269\n",
      "2m 15s (- 6m 28s) (14100 25%) 0.0347\n",
      "2m 16s (- 6m 27s) (14200 26%) 0.0050\n",
      "2m 17s (- 6m 26s) (14300 26%) 0.0095\n",
      "2m 18s (- 6m 25s) (14400 26%) 0.0020\n",
      "2m 19s (- 6m 24s) (14500 26%) 0.0922\n",
      "2m 20s (- 6m 23s) (14600 26%) 0.0049\n",
      "2m 21s (- 6m 22s) (14700 27%) 0.0206\n",
      "2m 22s (- 6m 21s) (14800 27%) 0.0926\n",
      "2m 23s (- 6m 21s) (14900 27%) 0.0058\n",
      "2m 24s (- 6m 20s) (15000 27%) 0.0557\n",
      "2m 25s (- 6m 19s) (15100 27%) 0.0495\n",
      "2m 26s (- 6m 18s) (15200 27%) 0.0231\n",
      "2m 27s (- 6m 17s) (15300 28%) 0.0107\n",
      "2m 28s (- 6m 16s) (15400 28%) 0.0162\n",
      "2m 29s (- 6m 15s) (15500 28%) 0.0101\n",
      "2m 30s (- 6m 15s) (15600 28%) 0.0048\n",
      "2m 31s (- 6m 14s) (15700 28%) 0.0114\n",
      "2m 32s (- 6m 13s) (15800 29%) 0.0147\n",
      "2m 33s (- 6m 12s) (15900 29%) 0.0082\n",
      "2m 34s (- 6m 11s) (16000 29%) 0.0194\n",
      "2m 35s (- 6m 10s) (16100 29%) 0.0028\n",
      "2m 36s (- 6m 9s) (16200 29%) 0.0021\n",
      "2m 37s (- 6m 8s) (16300 29%) 0.0012\n",
      "2m 38s (- 6m 7s) (16400 30%) 0.0667\n",
      "2m 39s (- 6m 6s) (16500 30%) 0.1076\n",
      "2m 40s (- 6m 5s) (16600 30%) 0.0019\n",
      "2m 41s (- 6m 4s) (16700 30%) 0.0843\n",
      "2m 42s (- 6m 3s) (16800 30%) 0.0259\n",
      "2m 43s (- 6m 2s) (16900 31%) 0.0022\n",
      "2m 44s (- 6m 1s) (17000 31%) 0.0182\n",
      "2m 45s (- 6m 0s) (17100 31%) 0.0352\n",
      "2m 46s (- 5m 59s) (17200 31%) 0.0283\n",
      "2m 47s (- 5m 58s) (17300 31%) 0.0376\n",
      "2m 48s (- 5m 57s) (17400 31%) 0.0130\n",
      "2m 49s (- 5m 56s) (17500 32%) 0.0544\n",
      "2m 50s (- 5m 55s) (17600 32%) 0.0149\n",
      "2m 50s (- 5m 54s) (17700 32%) 0.0263\n",
      "2m 51s (- 5m 53s) (17800 32%) 0.0313\n",
      "2m 52s (- 5m 52s) (17900 32%) 0.1167\n",
      "2m 53s (- 5m 51s) (18000 33%) 0.0067\n",
      "2m 54s (- 5m 50s) (18100 33%) 0.0123\n",
      "2m 55s (- 5m 49s) (18200 33%) 0.0035\n",
      "2m 56s (- 5m 48s) (18300 33%) 0.2448\n",
      "2m 57s (- 5m 47s) (18400 33%) 0.0775\n",
      "2m 58s (- 5m 46s) (18500 33%) 0.1061\n",
      "2m 59s (- 5m 45s) (18600 34%) 0.0447\n",
      "3m 0s (- 5m 44s) (18700 34%) 0.0790\n",
      "3m 1s (- 5m 43s) (18800 34%) 0.0661\n",
      "3m 2s (- 5m 42s) (18900 34%) 0.0370\n",
      "3m 3s (- 5m 41s) (19000 34%) 0.0198\n",
      "3m 4s (- 5m 40s) (19100 35%) 0.0415\n",
      "3m 5s (- 5m 39s) (19200 35%) 0.0216\n",
      "3m 6s (- 5m 38s) (19300 35%) 0.0294\n",
      "3m 7s (- 5m 37s) (19400 35%) 0.0573\n",
      "3m 8s (- 5m 36s) (19500 35%) 0.0684\n",
      "3m 9s (- 5m 35s) (19600 36%) 0.0199\n",
      "3m 10s (- 5m 35s) (19700 36%) 0.0120\n",
      "3m 11s (- 5m 34s) (19800 36%) 0.0105\n",
      "3m 11s (- 5m 33s) (19900 36%) 0.0250\n",
      "3m 12s (- 5m 32s) (20000 36%) 0.0290\n",
      "3m 13s (- 5m 31s) (20100 36%) 0.0323\n",
      "3m 14s (- 5m 30s) (20200 37%) 0.0112\n",
      "3m 15s (- 5m 29s) (20300 37%) 0.0286\n",
      "3m 16s (- 5m 28s) (20400 37%) 0.0159\n",
      "3m 17s (- 5m 27s) (20500 37%) 0.0918\n",
      "3m 18s (- 5m 26s) (20600 37%) 0.0495\n",
      "3m 19s (- 5m 25s) (20700 38%) 0.0145\n",
      "3m 20s (- 5m 24s) (20800 38%) 0.1459\n",
      "3m 21s (- 5m 23s) (20900 38%) 0.0359\n",
      "3m 22s (- 5m 22s) (21000 38%) 0.1100\n",
      "3m 23s (- 5m 21s) (21100 38%) 0.0844\n",
      "3m 24s (- 5m 20s) (21200 38%) 0.0764\n",
      "3m 25s (- 5m 19s) (21300 39%) 0.0562\n",
      "3m 26s (- 5m 19s) (21400 39%) 0.0233\n",
      "3m 27s (- 5m 18s) (21500 39%) 0.0462\n",
      "3m 28s (- 5m 17s) (21600 39%) 0.0107\n",
      "3m 29s (- 5m 16s) (21700 39%) 0.0337\n",
      "3m 30s (- 5m 15s) (21800 40%) 0.0315\n",
      "3m 31s (- 5m 14s) (21900 40%) 0.0920\n",
      "3m 32s (- 5m 13s) (22000 40%) 0.0351\n",
      "3m 33s (- 5m 12s) (22100 40%) 0.0075\n",
      "3m 34s (- 5m 11s) (22200 40%) 0.0167\n",
      "3m 35s (- 5m 10s) (22300 40%) 0.0810\n",
      "3m 36s (- 5m 9s) (22400 41%) 0.0380\n",
      "3m 37s (- 5m 8s) (22500 41%) 0.0217\n",
      "3m 38s (- 5m 7s) (22600 41%) 0.0063\n",
      "3m 39s (- 5m 7s) (22700 41%) 0.0057\n",
      "3m 40s (- 5m 6s) (22800 41%) 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 41s (- 5m 5s) (22900 42%) 0.0564\n",
      "3m 42s (- 5m 4s) (23000 42%) 0.0093\n",
      "3m 43s (- 5m 3s) (23100 42%) 0.0074\n",
      "3m 44s (- 5m 2s) (23200 42%) 0.0145\n",
      "3m 45s (- 5m 1s) (23300 42%) 0.0207\n",
      "3m 46s (- 5m 0s) (23400 42%) 0.1014\n",
      "3m 47s (- 4m 59s) (23500 43%) 0.2554\n",
      "3m 48s (- 4m 58s) (23600 43%) 0.0104\n",
      "3m 49s (- 4m 57s) (23700 43%) 0.1549\n",
      "3m 50s (- 4m 56s) (23800 43%) 0.0339\n",
      "3m 51s (- 4m 55s) (23900 43%) 0.0180\n",
      "3m 52s (- 4m 54s) (24000 44%) 0.0666\n",
      "3m 53s (- 4m 53s) (24100 44%) 0.0230\n",
      "3m 54s (- 4m 52s) (24200 44%) 0.1356\n",
      "3m 55s (- 4m 51s) (24300 44%) 0.0073\n",
      "3m 56s (- 4m 50s) (24400 44%) 0.0247\n",
      "3m 57s (- 4m 49s) (24500 45%) 0.0180\n",
      "3m 58s (- 4m 48s) (24600 45%) 0.0206\n",
      "3m 59s (- 4m 47s) (24700 45%) 0.0376\n",
      "4m 0s (- 4m 46s) (24800 45%) 0.1060\n",
      "4m 1s (- 4m 45s) (24900 45%) 0.0077\n",
      "4m 2s (- 4m 44s) (25000 45%) 0.0080\n",
      "4m 2s (- 4m 43s) (25100 46%) 0.0423\n",
      "4m 3s (- 4m 43s) (25200 46%) 0.0569\n",
      "4m 4s (- 4m 42s) (25300 46%) 0.0621\n",
      "4m 5s (- 4m 41s) (25400 46%) 0.1197\n",
      "4m 6s (- 4m 40s) (25500 46%) 0.0841\n",
      "4m 7s (- 4m 39s) (25600 47%) 0.0463\n",
      "4m 8s (- 4m 38s) (25700 47%) 0.0370\n",
      "4m 9s (- 4m 37s) (25800 47%) 0.0248\n",
      "4m 10s (- 4m 36s) (25900 47%) 0.0119\n",
      "4m 11s (- 4m 35s) (26000 47%) 0.0620\n",
      "4m 12s (- 4m 34s) (26100 47%) 0.0669\n",
      "4m 13s (- 4m 33s) (26200 48%) 0.0235\n",
      "4m 14s (- 4m 32s) (26300 48%) 0.0362\n",
      "4m 15s (- 4m 31s) (26400 48%) 0.3767\n",
      "4m 16s (- 4m 30s) (26500 48%) 0.0549\n",
      "4m 17s (- 4m 29s) (26600 48%) 0.0559\n",
      "4m 18s (- 4m 28s) (26700 49%) 0.0172\n",
      "4m 19s (- 4m 27s) (26800 49%) 0.0132\n",
      "4m 20s (- 4m 26s) (26900 49%) 0.0091\n",
      "4m 21s (- 4m 25s) (27000 49%) 0.0045\n",
      "4m 22s (- 4m 24s) (27100 49%) 0.1757\n",
      "4m 23s (- 4m 23s) (27200 49%) 0.0507\n",
      "4m 24s (- 4m 22s) (27300 50%) 0.0124\n",
      "4m 25s (- 4m 21s) (27400 50%) 0.0175\n",
      "4m 26s (- 4m 21s) (27500 50%) 0.0100\n",
      "4m 27s (- 4m 20s) (27600 50%) 0.0105\n",
      "4m 28s (- 4m 19s) (27700 50%) 0.0842\n",
      "4m 29s (- 4m 18s) (27800 51%) 0.0212\n",
      "4m 30s (- 4m 17s) (27900 51%) 0.2629\n",
      "4m 31s (- 4m 16s) (28000 51%) 0.1358\n",
      "4m 32s (- 4m 15s) (28100 51%) 0.0657\n",
      "4m 33s (- 4m 14s) (28200 51%) 0.0107\n",
      "4m 34s (- 4m 13s) (28300 51%) 0.0108\n",
      "4m 35s (- 4m 12s) (28400 52%) 0.0614\n",
      "4m 35s (- 4m 11s) (28500 52%) 0.0132\n",
      "4m 36s (- 4m 10s) (28600 52%) 0.0417\n",
      "4m 37s (- 4m 9s) (28700 52%) 0.0160\n",
      "4m 38s (- 4m 8s) (28800 52%) 0.0115\n",
      "4m 39s (- 4m 7s) (28900 53%) 0.0120\n",
      "4m 40s (- 4m 6s) (29000 53%) 0.0073\n",
      "4m 41s (- 4m 5s) (29100 53%) 0.0209\n",
      "4m 42s (- 4m 4s) (29200 53%) 0.0128\n",
      "4m 43s (- 4m 3s) (29300 53%) 0.0126\n",
      "4m 44s (- 4m 2s) (29400 54%) 0.0031\n",
      "4m 45s (- 4m 1s) (29500 54%) 0.0116\n",
      "4m 46s (- 4m 0s) (29600 54%) 0.0106\n",
      "4m 47s (- 3m 59s) (29700 54%) 0.2037\n",
      "4m 48s (- 3m 58s) (29800 54%) 0.0183\n",
      "4m 49s (- 3m 57s) (29900 54%) 0.0173\n",
      "4m 50s (- 3m 56s) (30000 55%) 0.0302\n",
      "4m 51s (- 3m 55s) (30100 55%) 0.0180\n",
      "4m 52s (- 3m 54s) (30200 55%) 0.0041\n",
      "4m 53s (- 3m 53s) (30300 55%) 0.0047\n",
      "4m 54s (- 3m 52s) (30400 55%) 0.0422\n",
      "4m 55s (- 3m 51s) (30500 56%) 0.0253\n",
      "4m 56s (- 3m 50s) (30600 56%) 0.0024\n",
      "4m 57s (- 3m 50s) (30700 56%) 0.0027\n",
      "4m 58s (- 3m 49s) (30800 56%) 0.0033\n",
      "4m 59s (- 3m 48s) (30900 56%) 0.0027\n",
      "5m 0s (- 3m 47s) (31000 56%) 0.0881\n",
      "5m 1s (- 3m 46s) (31100 57%) 0.0374\n",
      "5m 2s (- 3m 45s) (31200 57%) 0.0088\n",
      "5m 3s (- 3m 44s) (31300 57%) 0.0053\n",
      "5m 4s (- 3m 43s) (31400 57%) 0.0042\n",
      "5m 5s (- 3m 42s) (31500 57%) 0.0115\n",
      "5m 6s (- 3m 41s) (31600 58%) 0.0045\n",
      "5m 7s (- 3m 40s) (31700 58%) 0.0020\n",
      "5m 8s (- 3m 39s) (31800 58%) 0.0021\n",
      "5m 9s (- 3m 38s) (31900 58%) 0.0346\n",
      "5m 10s (- 3m 37s) (32000 58%) 0.0023\n",
      "5m 11s (- 3m 36s) (32100 58%) 0.0037\n",
      "5m 12s (- 3m 35s) (32200 59%) 0.0299\n",
      "5m 13s (- 3m 34s) (32300 59%) 0.0051\n",
      "5m 14s (- 3m 33s) (32400 59%) 0.0118\n",
      "5m 15s (- 3m 32s) (32500 59%) 0.0108\n",
      "5m 16s (- 3m 31s) (32600 59%) 0.1465\n",
      "5m 17s (- 3m 30s) (32700 60%) 0.0040\n",
      "5m 18s (- 3m 29s) (32800 60%) 0.0431\n",
      "5m 19s (- 3m 29s) (32900 60%) 0.1506\n",
      "5m 20s (- 3m 28s) (33000 60%) 0.0372\n",
      "5m 21s (- 3m 27s) (33100 60%) 0.0056\n",
      "5m 22s (- 3m 26s) (33200 60%) 0.0129\n",
      "5m 23s (- 3m 25s) (33300 61%) 0.0061\n",
      "5m 24s (- 3m 24s) (33400 61%) 0.0100\n",
      "5m 25s (- 3m 23s) (33500 61%) 0.0582\n",
      "5m 26s (- 3m 22s) (33600 61%) 0.0071\n",
      "5m 27s (- 3m 21s) (33700 61%) 0.0034\n",
      "5m 28s (- 3m 20s) (33800 62%) 0.0982\n",
      "5m 29s (- 3m 19s) (33900 62%) 0.0555\n",
      "5m 30s (- 3m 18s) (34000 62%) 0.0086\n",
      "5m 31s (- 3m 17s) (34100 62%) 0.0052\n",
      "5m 32s (- 3m 16s) (34200 62%) 0.0483\n",
      "5m 32s (- 3m 15s) (34300 63%) 0.1132\n",
      "5m 33s (- 3m 14s) (34400 63%) 0.0277\n",
      "5m 34s (- 3m 13s) (34500 63%) 0.2908\n",
      "5m 35s (- 3m 12s) (34600 63%) 0.0690\n",
      "5m 36s (- 3m 11s) (34700 63%) 0.0324\n",
      "5m 37s (- 3m 10s) (34800 63%) 0.0333\n",
      "5m 38s (- 3m 9s) (34900 64%) 0.0290\n",
      "5m 39s (- 3m 8s) (35000 64%) 0.0298\n",
      "5m 40s (- 3m 7s) (35100 64%) 0.0631\n",
      "5m 41s (- 3m 6s) (35200 64%) 0.0629\n",
      "5m 42s (- 3m 5s) (35300 64%) 0.0092\n",
      "5m 43s (- 3m 4s) (35400 65%) 0.0132\n",
      "5m 44s (- 3m 3s) (35500 65%) 0.0293\n",
      "5m 45s (- 3m 2s) (35600 65%) 0.1488\n",
      "5m 46s (- 3m 1s) (35700 65%) 0.0050\n",
      "5m 47s (- 3m 0s) (35800 65%) 0.0455\n",
      "5m 48s (- 2m 59s) (35900 65%) 0.0195\n",
      "5m 49s (- 2m 58s) (36000 66%) 0.0872\n",
      "5m 50s (- 2m 57s) (36100 66%) 0.0303\n",
      "5m 51s (- 2m 56s) (36200 66%) 0.1326\n",
      "5m 52s (- 2m 55s) (36300 66%) 0.0074\n",
      "5m 53s (- 2m 54s) (36400 66%) 0.0496\n",
      "5m 54s (- 2m 53s) (36500 67%) 0.0686\n",
      "5m 55s (- 2m 53s) (36600 67%) 0.0520\n",
      "5m 56s (- 2m 52s) (36700 67%) 0.0682\n",
      "5m 57s (- 2m 51s) (36800 67%) 0.1192\n",
      "5m 58s (- 2m 50s) (36900 67%) 0.0147\n",
      "5m 59s (- 2m 49s) (37000 67%) 0.0393\n",
      "6m 0s (- 2m 48s) (37100 68%) 0.0471\n",
      "6m 1s (- 2m 47s) (37200 68%) 0.0078\n",
      "6m 1s (- 2m 46s) (37300 68%) 0.0980\n",
      "6m 2s (- 2m 45s) (37400 68%) 0.0249\n",
      "6m 3s (- 2m 44s) (37500 68%) 0.0154\n",
      "6m 4s (- 2m 43s) (37600 69%) 0.0601\n",
      "6m 5s (- 2m 42s) (37700 69%) 0.2103\n",
      "6m 6s (- 2m 41s) (37800 69%) 0.0195\n",
      "6m 7s (- 2m 40s) (37900 69%) 0.0311\n",
      "6m 8s (- 2m 39s) (38000 69%) 0.0250\n",
      "6m 9s (- 2m 38s) (38100 69%) 0.0398\n",
      "6m 10s (- 2m 37s) (38200 70%) 0.0138\n",
      "6m 11s (- 2m 36s) (38300 70%) 0.0176\n",
      "6m 12s (- 2m 35s) (38400 70%) 0.0167\n",
      "6m 13s (- 2m 34s) (38500 70%) 0.0106\n",
      "6m 14s (- 2m 33s) (38600 70%) 0.0266\n",
      "6m 15s (- 2m 32s) (38700 71%) 0.0133\n",
      "6m 16s (- 2m 31s) (38800 71%) 0.0077\n",
      "6m 17s (- 2m 30s) (38900 71%) 0.0185\n",
      "6m 18s (- 2m 29s) (39000 71%) 0.0192\n",
      "6m 19s (- 2m 28s) (39100 71%) 0.0083\n",
      "6m 20s (- 2m 27s) (39200 72%) 0.0941\n",
      "6m 21s (- 2m 26s) (39300 72%) 0.0154\n",
      "6m 22s (- 2m 25s) (39400 72%) 0.0036\n",
      "6m 23s (- 2m 24s) (39500 72%) 0.0492\n",
      "6m 24s (- 2m 24s) (39600 72%) 0.0122\n",
      "6m 25s (- 2m 23s) (39700 72%) 0.0047\n",
      "6m 26s (- 2m 22s) (39800 73%) 0.0323\n",
      "6m 27s (- 2m 21s) (39900 73%) 0.0151\n",
      "6m 28s (- 2m 20s) (40000 73%) 0.0255\n",
      "6m 29s (- 2m 19s) (40100 73%) 0.0057\n",
      "6m 30s (- 2m 18s) (40200 73%) 0.0258\n",
      "6m 31s (- 2m 17s) (40300 74%) 0.0362\n",
      "6m 32s (- 2m 16s) (40400 74%) 0.0030\n",
      "6m 33s (- 2m 15s) (40500 74%) 0.0077\n",
      "6m 34s (- 2m 14s) (40600 74%) 0.0022\n",
      "6m 35s (- 2m 13s) (40700 74%) 0.0163\n",
      "6m 36s (- 2m 12s) (40800 74%) 0.0219\n",
      "6m 37s (- 2m 11s) (40900 75%) 0.0224\n",
      "6m 38s (- 2m 10s) (41000 75%) 0.0089\n",
      "6m 39s (- 2m 9s) (41100 75%) 0.0524\n",
      "6m 40s (- 2m 8s) (41200 75%) 0.3243\n",
      "6m 41s (- 2m 7s) (41300 75%) 0.0240\n",
      "6m 42s (- 2m 6s) (41400 76%) 0.0157\n",
      "6m 43s (- 2m 5s) (41500 76%) 0.0463\n",
      "6m 44s (- 2m 4s) (41600 76%) 0.0889\n",
      "6m 44s (- 2m 3s) (41700 76%) 0.0494\n",
      "6m 45s (- 2m 2s) (41800 76%) 0.1114\n",
      "6m 46s (- 2m 1s) (41900 76%) 0.1847\n",
      "6m 47s (- 2m 0s) (42000 77%) 0.0219\n",
      "6m 48s (- 1m 59s) (42100 77%) 0.0050\n",
      "6m 49s (- 1m 58s) (42200 77%) 0.0809\n",
      "6m 50s (- 1m 57s) (42300 77%) 0.0202\n",
      "6m 51s (- 1m 56s) (42400 77%) 0.0171\n",
      "6m 52s (- 1m 55s) (42500 78%) 0.0088\n",
      "6m 53s (- 1m 54s) (42600 78%) 0.0030\n",
      "6m 54s (- 1m 53s) (42700 78%) 0.0185\n",
      "6m 55s (- 1m 52s) (42800 78%) 0.0226\n",
      "6m 56s (- 1m 51s) (42900 78%) 0.0122\n",
      "6m 57s (- 1m 50s) (43000 78%) 0.0250\n",
      "6m 58s (- 1m 50s) (43100 79%) 0.0459\n",
      "6m 59s (- 1m 49s) (43200 79%) 0.0029\n",
      "7m 0s (- 1m 48s) (43300 79%) 0.1948\n",
      "7m 1s (- 1m 47s) (43400 79%) 0.0479\n",
      "7m 2s (- 1m 46s) (43500 79%) 0.0745\n",
      "7m 3s (- 1m 45s) (43600 80%) 0.0483\n",
      "7m 4s (- 1m 44s) (43700 80%) 0.0084\n",
      "7m 5s (- 1m 43s) (43800 80%) 0.0067\n",
      "7m 6s (- 1m 42s) (43900 80%) 0.0573\n",
      "7m 7s (- 1m 41s) (44000 80%) 0.0031\n",
      "7m 8s (- 1m 40s) (44100 81%) 0.0048\n",
      "7m 9s (- 1m 39s) (44200 81%) 0.0026\n",
      "7m 10s (- 1m 38s) (44300 81%) 0.0033\n",
      "7m 11s (- 1m 37s) (44400 81%) 0.0782\n",
      "7m 12s (- 1m 36s) (44500 81%) 0.0063\n",
      "7m 13s (- 1m 35s) (44600 81%) 0.0014\n",
      "7m 14s (- 1m 34s) (44700 82%) 0.0990\n",
      "7m 14s (- 1m 33s) (44800 82%) 0.0049\n",
      "7m 15s (- 1m 32s) (44900 82%) 0.0029\n",
      "7m 16s (- 1m 31s) (45000 82%) 0.0266\n",
      "7m 17s (- 1m 30s) (45100 82%) 0.0597\n",
      "7m 18s (- 1m 29s) (45200 83%) 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7m 19s (- 1m 28s) (45300 83%) 0.0028\n",
      "7m 20s (- 1m 27s) (45400 83%) 0.0086\n",
      "7m 21s (- 1m 26s) (45500 83%) 0.0017\n",
      "7m 22s (- 1m 25s) (45600 83%) 0.0297\n",
      "7m 23s (- 1m 24s) (45700 83%) 0.0032\n",
      "7m 24s (- 1m 23s) (45800 84%) 0.0113\n",
      "7m 25s (- 1m 22s) (45900 84%) 0.0008\n",
      "7m 26s (- 1m 21s) (46000 84%) 0.0030\n",
      "7m 27s (- 1m 20s) (46100 84%) 0.0006\n",
      "7m 28s (- 1m 19s) (46200 84%) 0.0006\n",
      "7m 29s (- 1m 19s) (46300 85%) 0.0026\n",
      "7m 30s (- 1m 18s) (46400 85%) 0.1307\n",
      "7m 31s (- 1m 17s) (46500 85%) 0.0424\n",
      "7m 32s (- 1m 16s) (46600 85%) 0.0044\n",
      "7m 33s (- 1m 15s) (46700 85%) 0.0013\n",
      "7m 34s (- 1m 14s) (46800 85%) 0.1013\n",
      "7m 35s (- 1m 13s) (46900 86%) 0.0024\n",
      "7m 36s (- 1m 12s) (47000 86%) 0.0023\n",
      "7m 37s (- 1m 11s) (47100 86%) 0.0254\n",
      "7m 38s (- 1m 10s) (47200 86%) 0.0014\n",
      "7m 39s (- 1m 9s) (47300 86%) 0.0031\n",
      "7m 40s (- 1m 8s) (47400 87%) 0.0061\n",
      "7m 41s (- 1m 7s) (47500 87%) 0.0091\n",
      "7m 42s (- 1m 6s) (47600 87%) 0.0045\n",
      "7m 43s (- 1m 5s) (47700 87%) 0.0230\n",
      "7m 44s (- 1m 4s) (47800 87%) 0.0015\n",
      "7m 45s (- 1m 3s) (47900 87%) 0.0021\n",
      "7m 46s (- 1m 2s) (48000 88%) 0.0023\n",
      "7m 47s (- 1m 1s) (48100 88%) 0.0153\n",
      "7m 48s (- 1m 0s) (48200 88%) 0.0039\n",
      "7m 49s (- 0m 59s) (48300 88%) 0.0329\n",
      "7m 50s (- 0m 58s) (48400 88%) 0.0026\n",
      "7m 51s (- 0m 57s) (48500 89%) 0.0587\n",
      "7m 52s (- 0m 56s) (48600 89%) 0.0007\n",
      "7m 53s (- 0m 55s) (48700 89%) 0.0106\n",
      "7m 54s (- 0m 54s) (48800 89%) 0.0007\n",
      "7m 55s (- 0m 53s) (48900 89%) 0.0361\n",
      "7m 56s (- 0m 52s) (49000 90%) 0.0068\n",
      "7m 57s (- 0m 51s) (49100 90%) 0.0864\n",
      "7m 58s (- 0m 50s) (49200 90%) 0.0399\n",
      "7m 59s (- 0m 49s) (49300 90%) 0.0353\n",
      "8m 0s (- 0m 48s) (49400 90%) 0.0012\n",
      "8m 1s (- 0m 47s) (49500 90%) 0.0185\n",
      "8m 2s (- 0m 46s) (49600 91%) 0.0014\n",
      "8m 3s (- 0m 46s) (49700 91%) 0.0047\n",
      "8m 4s (- 0m 45s) (49800 91%) 0.0025\n",
      "8m 5s (- 0m 44s) (49900 91%) 0.0028\n",
      "8m 6s (- 0m 43s) (50000 91%) 0.0015\n",
      "8m 7s (- 0m 42s) (50100 92%) 0.0018\n",
      "8m 8s (- 0m 41s) (50200 92%) 0.0670\n",
      "8m 9s (- 0m 40s) (50300 92%) 0.0027\n",
      "8m 10s (- 0m 39s) (50400 92%) 0.0033\n",
      "8m 11s (- 0m 38s) (50500 92%) 0.0012\n",
      "8m 12s (- 0m 37s) (50600 92%) 0.0059\n",
      "8m 13s (- 0m 36s) (50700 93%) 0.0314\n",
      "8m 14s (- 0m 35s) (50800 93%) 0.0241\n",
      "8m 15s (- 0m 34s) (50900 93%) 0.0019\n",
      "8m 16s (- 0m 33s) (51000 93%) 0.0007\n",
      "8m 17s (- 0m 32s) (51100 93%) 0.0008\n",
      "8m 18s (- 0m 31s) (51200 94%) 0.0013\n",
      "8m 18s (- 0m 30s) (51300 94%) 0.0007\n",
      "8m 19s (- 0m 29s) (51400 94%) 0.0079\n",
      "8m 20s (- 0m 28s) (51500 94%) 0.0017\n",
      "8m 21s (- 0m 27s) (51600 94%) 0.0004\n",
      "8m 22s (- 0m 26s) (51700 94%) 0.0010\n",
      "8m 23s (- 0m 25s) (51800 95%) 0.0550\n",
      "8m 24s (- 0m 24s) (51900 95%) 0.0497\n",
      "8m 25s (- 0m 23s) (52000 95%) 0.0057\n",
      "8m 26s (- 0m 22s) (52100 95%) 0.0010\n",
      "8m 27s (- 0m 21s) (52200 95%) 0.0012\n",
      "8m 28s (- 0m 20s) (52300 96%) 0.0018\n",
      "8m 29s (- 0m 19s) (52400 96%) 0.0011\n",
      "8m 30s (- 0m 18s) (52500 96%) 0.0413\n",
      "8m 31s (- 0m 17s) (52600 96%) 0.0028\n",
      "8m 32s (- 0m 16s) (52700 96%) 0.0049\n",
      "8m 33s (- 0m 15s) (52800 96%) 0.0013\n",
      "8m 34s (- 0m 14s) (52900 97%) 0.0017\n",
      "8m 35s (- 0m 13s) (53000 97%) 0.0006\n",
      "8m 36s (- 0m 12s) (53100 97%) 0.0010\n",
      "8m 37s (- 0m 11s) (53200 97%) 0.0008\n",
      "8m 38s (- 0m 11s) (53300 97%) 0.0009\n",
      "8m 39s (- 0m 10s) (53400 98%) 0.0014\n",
      "8m 40s (- 0m 9s) (53500 98%) 0.0012\n",
      "8m 41s (- 0m 8s) (53600 98%) 0.0018\n",
      "8m 42s (- 0m 7s) (53700 98%) 0.0007\n",
      "8m 43s (- 0m 6s) (53800 98%) 0.0330\n",
      "8m 44s (- 0m 5s) (53900 99%) 0.0013\n",
      "8m 45s (- 0m 4s) (54000 99%) 0.0010\n",
      "8m 46s (- 0m 3s) (54100 99%) 0.0022\n",
      "8m 47s (- 0m 2s) (54200 99%) 0.0015\n",
      "8m 47s (- 0m 1s) (54300 99%) 0.0014\n",
      "8m 48s (- 0m 0s) (54400 99%) 0.0538\n",
      "[1.072567953169346, 0.569070558398962, 0.43513432793319223, 0.335954307988286, 0.24844920074101537, 0.14388900710269809, 0.11516818878008053, 0.086333914011484, 0.060443580724531785, 0.051929780405480415, 0.06976564369397238, 0.049171940938103946, 0.10437625690014102, 0.04241136210272089, 0.01313287029915955, 0.024521382839884608, 0.05943798409600277, 0.007921558871748858, 0.029291751311102416, 0.07655024115665583, 0.005907646718842443, 0.0050410483035375365, 0.0306173403019784, 0.033079567220120225, 0.002964385210943874, 0.017768445999827236, 0.020884241403837222, 0.0054628435293852815, 0.01290267746677273, 0.06430346559020109, 0.019275925637193724, 0.018955695021431893, 0.0024681167663948146, 0.004000065332947997, 0.009145949977537385, 0.03215085570554947, 0.013108001955770306, 0.20484022630596882, 0.14279089998046401, 0.15768639825633726, 0.06926479728601408, 0.04945757540408522, 0.026953954342170617, 0.015966403066122438, 0.17268984457448824, 0.04199699366465211, 0.06011149390469654, 0.0291594803451153, 0.025391346605611032, 0.05046643704699818, 0.041632725914096225, 0.014367899656936061, 0.03926396212002146, 0.09612626508853282, 0.023933670669212006, 0.037893212777998994, 0.07363246359062031, 0.006956738332955865, 0.011210108090017457, 0.009259526553069008, 0.021323367278382646, 0.03161223890943802, 0.10933843866121606, 0.013107747267058585, 0.02292204345954815, 0.03584363856571145, 0.00297792348486837, 0.050556108650416716, 0.04458887656670413, 0.003731962047168054, 0.004219449188385624, 0.01777025397052057, 0.01329109065605735, 0.0034274559985351515, 0.013223248985377722, 0.01004686681975727, 0.0014005509241542314, 0.09505979486493743, 0.05832443323204643, 0.003986793199583189, 0.005929611146711977, 0.14764323189592687, 0.009472237489244435, 0.06452931339561474, 0.036413927375688215, 0.03504474228218896, 0.06626558490272146, 0.10029143566614948, 0.04768362572154729, 0.055421062590176005, 0.03941497915599029, 0.056756603602843826, 0.14475123989977873, 0.005331100005059852, 0.28774382722502195, 0.17013696762551261, 0.048662106189513, 0.007703559078508988, 0.012729368174623232, 0.004429684776696376, 0.02467469614231959, 0.005144742934498936, 0.0033881930133793504, 0.0027242706622200787, 0.0025919694414187687, 0.0028201799622911495, 0.0015897654684522422, 0.0013428199803456665, 0.002566404372410034, 0.0673978104058915, 0.006324844887421932, 0.001320251538127195, 0.004613262022830895, 0.1346173024163727, 0.03049737319604901, 0.004504600747823133, 0.013429146951166331, 0.012922147319914075, 0.017471339616568004, 0.18931520911348343, 0.06241781113654724, 0.0036293801222927868, 0.1400947755613015, 0.04404362517176196, 0.12649898383941036, 0.14259543702122757, 0.016775646324967964, 0.1535417815076653, 0.05055159912444651, 0.008852652180648875, 0.15086722957203164, 0.10083066900027916, 0.10124200110207311, 0.06600143653340637, 0.03223666108911857, 0.13636361709126504, 0.06811910866468679, 0.09095209109626012, 0.008193402548640734, 0.12688091274816543, 0.03472911586839473, 0.005031729773327243, 0.009463531569344923, 0.00196715968879289, 0.09223506467329572, 0.004854563779663295, 0.020605742146581178, 0.0925637745828135, 0.005753774869808694, 0.05571483061823528, 0.04949077131925151, 0.02308203405351378, 0.010749705069465564, 0.016171164032712113, 0.010084879694477421, 0.004764956662838813, 0.011403172865248052, 0.01468510650236567, 0.008195185471122387, 0.019444070030367584, 0.0027779072725388687, 0.002069008139515063, 0.001229555219397298, 0.06671296894950501, 0.10758102722713375, 0.0018809928942937404, 0.0842867365226266, 0.025927101864508587, 0.002195051022863481, 0.018249028345162514, 0.03517619639271288, 0.028339153232227545, 0.037587897176999834, 0.012950075460976223, 0.05437195124133723, 0.01487516126697301, 0.026314737295761007, 0.03129951669092407, 0.11673310319398297, 0.006736555451061577, 0.012254231319966493, 0.003539744579611579, 0.24480190117108577, 0.077515674779861, 0.10613318711315514, 0.044682191779284036, 0.07898869786979049, 0.06606555977617973, 0.03696931541533559, 0.01980584510049084, 0.041456578898214504, 0.02164122095739003, 0.029350057763440417, 0.057342191763964365, 0.06843869990389066, 0.019857241611825883, 0.011998665679639088, 0.010544886232237332, 0.025032849866402102, 0.028957574007945366, 0.032266733946744355, 0.011229007426300086, 0.028593611847245484, 0.01593215948319994, 0.09179500534817635, 0.049492687306410516, 0.014521831549500349, 0.14592521709819267, 0.03592053393702372, 0.11002833414357155, 0.0843512271020154, 0.07642521884503367, 0.0561510166622611, 0.023275454012909903, 0.046191880110127384, 0.010740700633105007, 0.03371691829132033, 0.03147168969593622, 0.09197004926278168, 0.03514772920119867, 0.007474887442331237, 0.016686299578868784, 0.08102194379331194, 0.03801218744978541, 0.021703725641564232, 0.006337322715116897, 0.005726530921238009, 0.003213673982754699, 0.05637566012723255, 0.00925747330627928, 0.0074294348321200234, 0.014461260612479236, 0.020662426086710185, 0.1014113009448556, 0.2554328150555375, 0.010351560895796865, 0.1549036021636857, 0.03386422010400565, 0.017993867293698715, 0.06656271217972971, 0.02301646684660227, 0.13563503108161967, 0.007291470972413663, 0.02469446113682352, 0.017963739739207084, 0.020554489957285114, 0.03755458500701934, 0.10604571193514857, 0.00771207163517829, 0.007997849111270626, 0.042322657693875956, 0.05693526970753737, 0.0621303651859489, 0.11971076946538232, 0.0840666693165258, 0.046334150575276, 0.03695707137012505, 0.024788725994440028, 0.011871921022539027, 0.06204385240605916, 0.0668614673297634, 0.02352835723442695, 0.03617452858801698, 0.37668246548390016, 0.05491617427498568, 0.05594291000656085, 0.01719661447335966, 0.013228921187401283, 0.009090972533158492, 0.004515325193788158, 0.17570142298180144, 0.050743547168531224, 0.01240633880996029, 0.01752989542204887, 0.01001151322176156, 0.010513869204878575, 0.08415879562860937, 0.02123121910408372, 0.26286866178939816, 0.1358247853681678, 0.06568916357588023, 0.010735238023335114, 0.010799959775467868, 0.06141830905806273, 0.01317229683685582, 0.041725329835899175, 0.016006444904196542, 0.011538298710947857, 0.01200466105248779, 0.007275973185314797, 0.02088762902945746, 0.012795496617691242, 0.012632164566166466, 0.003063982525563915, 0.011614141867758008, 0.010628830480927718, 0.20365468746516854, 0.018341153747896896, 0.0172753619265859, 0.03022915974142961, 0.018031669730189607, 0.004068325623229611, 0.004727577788798953, 0.04224744183156872, 0.025345316722523423, 0.002365425622701878, 0.0027395122438610997, 0.0033489848990575413, 0.0026882707011827733, 0.08809566853422439, 0.03744614970564726, 0.008754655196680687, 0.005319889376260108, 0.0041687717479362615, 0.011483382337464718, 0.004544943645523745, 0.0019507128706027289, 0.002124917927212664, 0.034589762759351286, 0.0022882412275794196, 0.0036781668135517976, 0.029931297784096388, 0.005132797335463692, 0.011849164042796474, 0.010778750854442479, 0.14647828751592898, 0.004021733514018706, 0.04305540208762977, 0.1505841219626018, 0.03718919062899659, 0.005636291638948024, 0.01292143926883, 0.006099847228470025, 0.01004856135121372, 0.05822841398883611, 0.007134662421303801, 0.003443732322921278, 0.09819608888472431, 0.05553955238196068, 0.0086038446117891, 0.005226888793476974, 0.04826648597460007, 0.11317133402160834, 0.027719326151564017, 0.2908396768759121, 0.06898404039384332, 0.032442750664195046, 0.03331489915319253, 0.029034063295111993, 0.029757274261210113, 0.06311038579166052, 0.06292058319348143, 0.00920626220817212, 0.013247380548127694, 0.02932845471368637, 0.1487785345946031, 0.0050336836819769816, 0.045461145560257134, 0.019474484586680774, 0.08717802124359877, 0.0302522005760693, 0.13255888495608814, 0.00736744136447669, 0.04963257142328075, 0.06858810717967571, 0.052026338308496636, 0.06815803451398096, 0.11922366968166898, 0.014662703660433181, 0.039289803594292606, 0.04708736704837065, 0.0077716893228353, 0.09799911003676243, 0.02485741364900605, 0.015374113620637217, 0.060141278074152066, 0.21032427775702672, 0.019525533724809065, 0.031146553903818132, 0.025006276627245826, 0.039760192248504606, 0.013831937879294855, 0.01758683231077157, 0.016737160706543363, 0.010602763128699734, 0.026564013767347204, 0.013343363191233948, 0.007654060916684103, 0.018524368255020816, 0.01921159154469933, 0.008329581768048228, 0.09413236712338403, 0.015390759997972054, 0.003625337814737577, 0.04924363827238267, 0.012171823942117044, 0.0046713800299767174, 0.03233851395430975, 0.015140431360923684, 0.025516645865718602, 0.0056604159213748065, 0.02581230803960352, 0.03619590358153801, 0.0029998592066112907, 0.007730150524294004, 0.0022380640235496684, 0.01628861199984385, 0.021914760332001605, 0.022365799257531762, 0.008872388116760704, 0.052440621420973915, 0.3242724529776024, 0.02399162659057765, 0.015745695680379868, 0.04633077953592874, 0.08891674017009792, 0.049425268970662725, 0.11141822720033816, 0.18473572699178475, 0.021893841779674402, 0.0050180288444971665, 0.08094022266479442, 0.020162813464412465, 0.017051658052660058, 0.008752106296597048, 0.0030498713583801875, 0.01854566112626344, 0.02260753717084299, 0.012239436795643996, 0.025021077833807793, 0.04591416835726705, 0.0028682564236805776, 0.19479754564061294, 0.04785897555644624, 0.07452550546484417, 0.04826560557179618, 0.008414050752180628, 0.006700956148561091, 0.05733706096740207, 0.003077405272051692, 0.004825561433972325, 0.0025831444418872706, 0.00332135020988062, 0.07815463215796627, 0.00631390667083906, 0.0014127762915450148, 0.09897725331116818, 0.0049028029741020876, 0.002874621414230205, 0.026629158598807406, 0.0597199007148447, 0.008261488063581054, 0.002798793542460771, 0.008612625954847318, 0.0016869926996878348, 0.029671394503384362, 0.003157873619638849, 0.011315601885944488, 0.0008117454355669907, 0.002956612950511044, 0.0006165603323461255, 0.0005868143656334723, 0.002578585124974779, 0.1306559137612203, 0.04239524152799277, 0.004420405938435579, 0.0012916031462373212, 0.1013185481011169, 0.002409185284777777, 0.0022716185986064374, 0.02536521132977214, 0.00140791235564393, 0.003095324054447701, 0.0061016631741949824, 0.009142612594441744, 0.004461637348576915, 0.022970622425782496, 0.0014958741273585474, 0.0020565693301614375, 0.002335828590730671, 0.015349855884633144, 0.003943619321580627, 0.03287024985809694, 0.002580815171240829, 0.058721885286067844, 0.000702414888801286, 0.010594408895849483, 0.000715860927302856, 0.03608436457125208, 0.0068027882786554986, 0.0864270938988193, 0.039946668958873485, 0.03527660704407026, 0.0012100064847618342, 0.01853791469009593, 0.0014458497587474994, 0.004739428150933236, 0.0024879817172768527, 0.0028337562175875064, 0.001471900080650812, 0.0018466860508488025, 0.06704282202801551, 0.0026897906442172824, 0.0032832743553444744, 0.001169694062846247, 0.005941515898157377, 0.03143636800312379, 0.024129959296114976, 0.0018613674539665226, 0.0007488699359237216, 0.0007880051413667388, 0.0013163904067187105, 0.0007047098490875214, 0.007870335203115246, 0.0016676228206779341, 0.00042684381536673755, 0.000997078944928944, 0.055029406272842606, 0.04968638862737862, 0.00565565925615374, 0.001041939262431697, 0.0011909743157593766, 0.001760207737243036, 0.0011375815939391031, 0.04132304953251151, 0.0027705543139745713, 0.0048838257164607055, 0.001250214993924601, 0.0017068238209321863, 0.0006145328580169007, 0.0009641474869931699, 0.0007500555369915673, 0.0009106431464169873, 0.0014406933611462592, 0.0012132194658988737, 0.001772901012118382, 0.0007167272461447283, 0.033045016100804785, 0.0012908876143774251, 0.0010269777636858636, 0.002178922568600683, 0.001537068410689244, 0.0013616456060117344, 0.05379532622160696]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[lang.index('<SOS>')]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == lang.index('<EOS>'):\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "epochs = 1\n",
    "encoder = EncoderRNN(lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, action_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "# Load state if exists, WARNING: DELETE FILES WHEN CHANGING MODEL \n",
    "if os.path.isfile('encoder.pt'):\n",
    "    encoder.load_state_dict(torch.load('encoder.pt'))\n",
    "if os.path.isfile('decoder.pt'):\n",
    "    decoder.load_state_dict(torch.load('decoder.pt'))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "plot_every = 100\n",
    "plot_losses = []\n",
    "print_every = 100\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "plot_loss_total = 0  # Reset every plot_every\n",
    "update = 0 # Counts updates\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "training_pairs = [sample for sample in low_action_pairs if len(sample[0]) < MAX_LENGTH and len(sample[1]) < MAX_LENGTH]\n",
    "update_count = len(training_pairs) * epochs\n",
    "print('updates: ', update_count)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in training_pairs:\n",
    "        update += 1\n",
    "        training_pair = batch\n",
    "        input_tensor = tensor_from_sentence(lang, training_pair[0])\n",
    "        target_tensor = tensor_from_sentence(action_lang, training_pair[1])\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if update % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (time_since(start, update / update_count),\n",
    "                                         update, (update / update_count) * 100, print_loss_avg))\n",
    "\n",
    "        if update % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "    # Save model\n",
    "    torch.save(encoder.state_dict(), 'encoder.pt')\n",
    "    torch.save(decoder.state_dict(), 'decoder.pt')\n",
    "\n",
    "print(plot_losses)\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-consumption",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "exempt-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pick up box with watch from couch -> ['PickupObject', '<EOS>'] (['PickupObject'])\n",
      "pick up the black pot on the counter -> ['PickupObject', '<EOS>'] (['PickupObject'])\n",
      "pick up a slice of lettuce -> ['PickupObject', '<EOS>'] (['PickupObject'])\n"
     ]
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, sentence, encoder_lang, decoder_lang, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensor_from_sentence(encoder_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[lang.index('<SOS>')]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == lang.index('<EOS>'):\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(decoder_lang.word(topi.item()))\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "for t in range(3):\n",
    "    sample = random.choice(training_pairs)\n",
    "    output = evaluate(encoder, decoder, sample[0], lang, action_lang)\n",
    "    print('%s -> %s (%s)' % (' '.join(sample[0]), output[0], sample[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
