{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal-Oriented Action Planner\n",
    "This notebook is home to my ideas about using GOAP, an AI system popular in video games (starting with the famous F.E.A.R game), to solve household tasks from natural language. The greatest difficulty in that challenge is translating natural language to actions, targets,  and behaviours.\n",
    "\n",
    "Much like how a graph is just a structured environment that is easy to reason about GOAP is an action planner that is easy to reason about. My hope is that GOAP can be a framework for completeing tasks that I can augment with learnable parameters. Putting the onus entirely on the language model to extract parameters for GOAP which in turn produces a plan which can satisfy our goal. \n",
    "\n",
    "GOAP needs:\n",
    "* Goals\n",
    "* Actions\n",
    "* Desired World State\n",
    "* Required World State (Not all actions require world state, e.g. Goto)\n",
    "\n",
    "Planning\n",
    "-------------\n",
    "Building a plan requires finding a valid goal then finding an action to satisfy that goal. What is clever is that goals often require state which searches action space and actions require state which again searches action space. Naturally you get heirachial planning. For example: Goal pick spoon requires world state of location of spoon. So action find spoon (which we assume the current world state satisfies its requirements) can search the graph many times over until found and then execute a plan for pick spoon.\n",
    "\n",
    "* Building a plan\n",
    "    * Find a valid goal\n",
    "    * Find an action that satisfies the goal\n",
    "    * Find an action that satisfies the previous action\n",
    "    * Repeat until the current world-state is matched\n",
    "* Use A* to path-find from goal's desired world-state to current world state.\n",
    "    * Path distance is a set cost per action\n",
    "    * Heuristic is the number of world-states that still need to be satisfied.\n",
    "    \n",
    "\n",
    "\n",
    "Rough pseudocode:\n",
    "-----------------------------\n",
    "We use a language model to read the instruction and produce a table of goals and world states. Then we run the planner with those using $A^*$ search and use the analytics to update the language model. \n",
    "In the beginning the table of goals and world states (GOAP params from now on) will be really bad and we wont get close to the target but it is my hope that we can tune this over many attempts.\n",
    "\n",
    "\n",
    "Language Model\n",
    "------------------------\n",
    "All these instructions define goals which boild down to constraint satisfaction. The language model serves to extract the constraint parameters. \"Bring me a coffee\" -> (node: Me, node: coffee). \"Put two objects on the table\" -> (node: table, node: two objects). The difficulty is in building these constraints in relation to the world. So the \"node\" terms must be searched for in the environment / state space using A*. \n",
    "\n",
    "What if goals and world state are represented by some latent vector?\n",
    "\n",
    "Building A* State Graph\n",
    "-----------------------------------\n",
    "Because we cannot know all the states because some are hidden we cannot exhastively search all states beforehand. What we must do is build the state graph while performing actions and update the world state for exploratory actions. E.g.: Action (open, drawer) -> New state -> Update all states to reflect this. ORRR If we assume that a goto action will never produce a new state and that only other actions can do that then only exlpore those actions. (that make new states). \n",
    "\n",
    "| Goals  | Requires World State  |\n",
    "|---|---|\n",
    "| \"Bring me a coffee\"  | (node: me, node: coffee) |\n",
    "| \"Put two objects on the table\"  | (node: table, node: object, node: object)  |\n",
    "| \"Wash the sponge\" | (node: clean sponge)  |\n",
    "\n",
    "Goals\n",
    "\n",
    "Requires World State\n",
    "\n",
    "*******************\n",
    "| Actions  | Satisfies World State | Requires World State  |\n",
    "|---|---|---|\n",
    "| \"goto\"  | (node: self, node: x) | () |\n",
    "| \"pickup\"  | (node: x, node: self)  | (node: self, node: x) |\n",
    "| \"putdown\"  | (node: x, node: y)(node:self, node: y)  | (node: x, node: y, node: self) |\n",
    "| \"transport\"  | (node: x, node: y) | (node: x, node: y) |\n",
    "| \"wash\" | (node: x, attribute: clean)  | (node: self, node: x)) |\n",
    "\n",
    "Actions\n",
    "\n",
    "Satisfies world state\n",
    "\n",
    "Requires World State\n",
    "\n",
    "*******************\n",
    "| Goals  |\n",
    "|---|\n",
    "| \"Bring me a coffee\"  |\n",
    "| \"Put two objects on the table\"  |\n",
    "| \"Wash the sponge\" |\n",
    "\n",
    "Current world state\n",
    "\n",
    "\n",
    "\n",
    "References\n",
    "-----------------\n",
    "Goal-Oriented Action Planning: Ten Years of AI Programming, Chris Conway, Peter Higley and Eric Jacopin\n",
    "https://www.youtube.com/watch?v=gm7K68663rA&t=1531s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla GOAP\n",
    "------------\n",
    "Using binary state. Consider adapting for graph state.\n",
    "The benefit of binary state is quick comparisons and masking (ignoring) variables we dont want to consider. For instance, a challenge is how do I use this to represent objects which can be placed anywhere? Should I make a bool for each constraint that can exist?? Perhaps binary state for landmark selection but a different state variable for objects with affordances? Food for thought.\n",
    "Also, forward or backward traversal? Backward seems to be the most common, ill start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Actions **\n",
      "scout\n",
      "approach\n",
      "aim\n",
      "shoot\n",
      "load\n",
      "detonatebomb\n",
      "flee\n",
      "** Atoms **\n",
      "armedwithgun\n",
      "enemyvisible\n",
      "nearenemy\n",
      "weaponloaded\n",
      "enemylinedup\n",
      "enemyalive\n",
      "armedwithbomb\n",
      "alive\n",
      "\n",
      "armedwithgun -> True\n",
      "enemyvisible -> False\n",
      "nearenemy -> False\n",
      "weaponloaded -> False\n",
      "enemylinedup -> False\n",
      "enemyalive -> True\n",
      "armedwithbomb -> True\n",
      "alive -> True\n",
      "\n",
      "goal: 0b0 0b100000\n",
      "******** PLAN ********\n",
      "plan:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'scout', 'load', 'aim', 'shoot']\n",
      "steps:  4\n"
     ]
    }
   ],
   "source": [
    "# State\n",
    "class State:\n",
    "    # An atom is a true/false state variable\n",
    "    state = 0 # Atoms state\n",
    "    mask = 0 # Atom mask\n",
    "    \n",
    "    def copy(self):\n",
    "        copy = State()\n",
    "        copy.state = self.state\n",
    "        copy.mask = self.mask\n",
    "        return copy\n",
    "\n",
    "MAX_ACTIONS = 64\n",
    "MAX_ATOMS = 64\n",
    "\n",
    "# Action Planner\n",
    "class ActionPlanner:\n",
    "    def __init__(self):\n",
    "        self.num_actions = 0\n",
    "        self.num_atoms = 0\n",
    "        self.action_names = [0 for i in range(MAX_ACTIONS)]\n",
    "        self.atom_names = [0 for i in range(MAX_ATOMS)]\n",
    "        self.action_costs = [1 for i in range(MAX_ACTIONS)]\n",
    "        self.action_pre_conditions = [State() for i in range(MAX_ACTIONS)] \n",
    "        self.action_post_conditions = [State() for i in range(MAX_ACTIONS)]\n",
    "    \n",
    "    def get_action_idx(self, action_name):\n",
    "        action_idx = 0\n",
    "        for idx in range(self.num_actions):\n",
    "            if action_name == self.action_names[idx]:\n",
    "                return action_idx\n",
    "            action_idx += 1\n",
    "        \n",
    "        # Action was not found, adding if space available\n",
    "        if action_idx < MAX_ACTIONS:\n",
    "            self.action_names[action_idx] = action_name\n",
    "            self.num_actions += 1\n",
    "            return action_idx\n",
    "        return -1\n",
    "    \n",
    "    def get_atom_idx(self, atom_name):\n",
    "        atom_idx = 0\n",
    "        for idx in range(self.num_atoms):\n",
    "            if atom_name == self.atom_names[idx]:\n",
    "                return atom_idx\n",
    "            atom_idx += 1\n",
    "        \n",
    "        # Atom was not found, adding if space available\n",
    "        if atom_idx < MAX_ATOMS:\n",
    "            self.atom_names[atom_idx] = atom_name\n",
    "            self.num_atoms += 1\n",
    "            return atom_idx\n",
    "        return -1\n",
    "    \n",
    "    def set_state(self, state, atom_name, value):\n",
    "        atom_idx = self.get_atom_idx(atom_name)\n",
    "        if atom_idx == -1:\n",
    "            return False\n",
    "        state.state = (state.state | (1 << atom_idx)) if value else (state.state & ~(1 << atom_idx))\n",
    "        state.mask = state.mask | (1 << atom_idx)\n",
    "        return True\n",
    "    \n",
    "    def set_pre_cond(self, action_name, atom_name, value):\n",
    "        action_idx = self.get_action_idx(action_name)\n",
    "        atom_idx = self.get_atom_idx(atom_name)\n",
    "        if action_idx == -1 or atom_idx == -1:\n",
    "            return False\n",
    "        self.set_state(self.action_pre_conditions[action_idx], atom_name, value)\n",
    "        return True\n",
    "    \n",
    "    def set_post_cond(self, action_name, atom_name, value):\n",
    "        action_idx = self.get_action_idx(action_name)\n",
    "        atom_idx = self.get_atom_idx(atom_name)\n",
    "        if action_idx == -1 or atom_idx == -1:\n",
    "            return False\n",
    "        self.set_state(self.action_post_conditions[action_idx], atom_name, value)\n",
    "        return True\n",
    "    \n",
    "    def do_action(self, action, from_state):\n",
    "        #print('*' * 10)\n",
    "        #print('DO ACTION: ', self.action_names[action], action)\n",
    "        #print('BEFORE STATE: ')\n",
    "        #self.print_state(from_state)\n",
    "        post_state = self.action_post_conditions[action]\n",
    "        affected_state_variables = post_state.mask\n",
    "        unaffected_state_variables = ~post_state.mask\n",
    "        \n",
    "        from_state.state = (from_state.state & unaffected_state_variables) | (post_state.state & affected_state_variables)\n",
    "        from_state.mask &= post_state.mask\n",
    "        #print('AFTER STATE: ')\n",
    "        #self.print_state(from_state)\n",
    "        return from_state\n",
    "\n",
    "    def get_possible_state_transitions(self, from_state, action_count):\n",
    "        to_states = []\n",
    "        action_names = []\n",
    "        action_costs = []\n",
    "        writer = 0\n",
    "        for i in range(self.num_actions):\n",
    "            if writer > action_count:\n",
    "                break\n",
    "            \n",
    "            # See if precondition is met\n",
    "            pre_state = self.action_pre_conditions[i]\n",
    "            affected_state_variables = pre_state.mask\n",
    "            met = (pre_state.state & affected_state_variables) == (from_state.state & affected_state_variables)\n",
    "            if met:\n",
    "                action_names.append(self.action_names[i])\n",
    "                action_costs.append(self.action_costs[i])\n",
    "                to_states.append(self.do_action(i, from_state.copy()))\n",
    "                writer+=1\n",
    "            \n",
    "        return writer, to_states, action_names, action_costs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.action_names = []\n",
    "        self.atom_names = []\n",
    "        self.action_pre_conditions = [State() for i in range(MAX_ACTIONS)] \n",
    "        self.action_post_conditions = [State() for i in range(MAX_ACTIONS)]\n",
    "    \n",
    "    def __str__(self):\n",
    "        print('** Actions **')\n",
    "        for idx in range(self.num_actions):\n",
    "            print(self.action_names[idx])\n",
    "        print('** Atoms **')\n",
    "        for idx in range(self.num_atoms):\n",
    "            print(self.atom_names[idx])\n",
    "        return \"\"\n",
    "    \n",
    "    def print_state(self, state):\n",
    "        for atom_idx in range(len(self.atom_names)):\n",
    "            if state.mask & (1 << atom_idx) != 0:\n",
    "                print(\"%s -> %r\" % (self.atom_names[atom_idx], (state.state & (1 << atom_idx)) != 0))\n",
    "\n",
    "class AStarNode:\n",
    "    state = 0 # State this node represents\n",
    "    parent_state = 0 # The state before this one\n",
    "    action_name = 0 # The action that derived this state\n",
    "    cost = 0 # Cost so far\n",
    "    remaining_cost = 0\n",
    "    f = 0 # Cost + remaining cost\n",
    "    \n",
    "    def copy(self):\n",
    "        copy = AStarNode()\n",
    "        copy.state = self.state\n",
    "        copy.parent_state = self.parent_state\n",
    "        copy.action_name = self.action_name\n",
    "        copy.cost = self.cost\n",
    "        copy.remaining_cost = self.remaining_cost\n",
    "        copy.f = self.f\n",
    "        return copy\n",
    "    \n",
    "\n",
    "MAX_OPEN = 1024\n",
    "MAX_CLOSED = 1024\n",
    "\n",
    "class AStarPlan:\n",
    "    def __init__(self, ap):\n",
    "        self.action_planner = ap\n",
    "        self.open = [0 for i in range(MAX_OPEN)] # Nodes to consider\n",
    "        self.closed = [0 for i in range(MAX_CLOSED)] # Visited nodes\n",
    "        self.num_open = 0\n",
    "        self.num_closed = 0\n",
    "    \n",
    "    def open_state_idx(self, state):\n",
    "        for i in range(self.num_open):\n",
    "            if self.open[i].state == state.state:\n",
    "                return i\n",
    "        return -1\n",
    "    \n",
    "    def closed_state_idx(self, _state):\n",
    "        for i in range(self.num_closed):\n",
    "            if self.closed[i].state.state == _state.state:\n",
    "                return i\n",
    "        return -1\n",
    "    \n",
    "    def reconstruct_plan(self, goal_node, plan_size):\n",
    "        # Retrace from last node to start node\n",
    "        plan = [0 for i in range(plan_size)]\n",
    "        states = [0 for i in range(plan_size)]\n",
    "        plan_idx = plan_size - 1\n",
    "        current_node = goal_node\n",
    "        steps = 0\n",
    "        while(current_node and current_node.action_name):\n",
    "            if plan_idx >= 0:\n",
    "                plan[plan_idx] = current_node.action_name\n",
    "                states[plan_idx] = current_node.state\n",
    "                i = self.closed_state_idx(current_node.parent_state)           \n",
    "                current_node = 0 if i == -1 else self.closed[i]\n",
    "            else:\n",
    "                print('plan size not big enough to completely reconstruct')\n",
    "                break\n",
    "            plan_idx -= 1\n",
    "            steps += 1\n",
    "        \n",
    "        return plan, states, steps\n",
    "    \n",
    "    def calculate_heuristic(self, state, goal_state):\n",
    "        return 1 # Placeholder for this example\n",
    "        \n",
    "#from: http://theory.stanford.edu/~amitp/GameProgramming/ImplementationNotes.html\n",
    "#OPEN = priority queue containing START\n",
    "#CLOSED = empty set\n",
    "#while lowest rank in OPEN is not the GOAL:\n",
    "#  current = remove lowest rank item from OPEN\n",
    "#  add current to CLOSED\n",
    "#  for neighbors of current:\n",
    "#    cost = g(current) + movementcost(current, neighbor)\n",
    "#    if neighbor in OPEN and cost less than g(neighbor):\n",
    "#      remove neighbor from OPEN, because new path is better\n",
    "#    if neighbor in CLOSED and cost less than g(neighbor): **\n",
    "#      remove neighbor from CLOSED\n",
    "#    if neighbor not in OPEN and neighbor not in CLOSED:\n",
    "#      set g(neighbor) to cost\n",
    "#      add neighbor to OPEN\n",
    "#      set priority queue rank to g(neighbor) + h(neighbor)\n",
    "#      set neighbor's parent to current\n",
    "\n",
    "    def plan(self, start_state, goal_state, plan_size):\n",
    "        start = AStarNode()\n",
    "        start.state = start_state\n",
    "        start.parent_state = start_state\n",
    "        start.action_name = 0\n",
    "        start.cost = 0\n",
    "        start.remaining_cost = self.calculate_heuristic(start_state, goal_state)\n",
    "        start.f = start.cost + start.remaining_cost\n",
    "        self.open[self.num_open] = start\n",
    "        self.num_open += 1\n",
    "        self.num_closed = 0\n",
    "        \n",
    "        while(True):\n",
    "            #print('NUM OPEN: ', self.num_open)\n",
    "            #print('NUM CLOSED: ', self.num_closed)\n",
    "            \n",
    "            # Lowest rank in OPEN that is not GOAL\n",
    "            if self.num_open == 0:\n",
    "                print(\"No path found\")\n",
    "                return -1\n",
    "            # Find node with lowest rank\n",
    "            lowest_idx = -1\n",
    "            lowest_value = 9999 # Our max int\n",
    "            for i in range(self.num_open):\n",
    "                if self.open[i].f  < lowest_value:\n",
    "                    lowest_value = self.open[i].f\n",
    "                    lowest_idx = i\n",
    "            \n",
    "            # Remove lowest rank node\n",
    "            current_node = self.open[lowest_idx]\n",
    "            if self.num_open:\n",
    "                self.open[lowest_idx] = self.open[self.num_open-1]\n",
    "            self.num_open -= 1\n",
    "            \n",
    "            # If current node state matches goal state, success\n",
    "            match = (current_node.state.state & goal_state.mask) == (goal_state.state & goal_state.mask)\n",
    "            \n",
    "            #print(current_node.action_name)\n",
    "            #print(bin(current_node.state.state & goal_state.mask))\n",
    "            #print(bin(goal_state.state & goal_state.mask))\n",
    "            #print(match)\n",
    "            \n",
    "            if match:\n",
    "                return self.reconstruct_plan(current_node, plan_size)\n",
    "            \n",
    "            # Add to closed\n",
    "            self.closed[self.num_closed] = current_node\n",
    "            self.num_closed+=1\n",
    "            \n",
    "            if self.num_closed == MAX_CLOSED:\n",
    "                print(\"Closed set overflow\")\n",
    "                return -1\n",
    "            \n",
    "            # Find neighbours\n",
    "            action_names = [0 for i in range(MAX_ACTIONS)]\n",
    "            action_costs = [0 for i in range(MAX_ACTIONS)]\n",
    "            to_states = [State() for i in range(MAX_ACTIONS)]\n",
    "            num_transitions, to_states, action_names, action_costs = self.action_planner.get_possible_state_transitions(current_node.state, MAX_ACTIONS)\n",
    "            \n",
    "            #print(\"NEIGHBOURS FOUND: \")\n",
    "            #print(num_transitions, action_names, action_costs)\n",
    "            #print(\"TO STATES:\")\n",
    "            #for s in to_states:\n",
    "            #    print(bin(s.state))\n",
    "            \n",
    "            for i in range(num_transitions):\n",
    "                neighbour = AStarNode()\n",
    "                cost = current_node.cost + action_costs[i]\n",
    "                idx_o = self.open_state_idx(to_states[i])\n",
    "                idx_c = self.closed_state_idx(to_states[i])\n",
    "                # If neighbour is in OPEN and cost less than g(neighbour)\n",
    "                if idx_o >= 0 and cost < self.open[idx_o].cost:\n",
    "                    # Remove neighbour from OPEN, because new path is better\n",
    "                    if self.num_open:\n",
    "                        self.open[idx_o] = self.open[self.num_open-1]\n",
    "                        self.num_open -= 1\n",
    "                        idx_o = -1 # // BUGFIX: neighbor is no longer in OPEN, signal this so that we can re-add it.\n",
    "                \n",
    "                # If neighbour is in CLOSED and cost less than g(neighbour)\n",
    "                if idx_c >= 0 and cost < self.closed[idx_c].cost:\n",
    "                    # Remove neighbour from CLOSED\n",
    "                    if self.num_closed:\n",
    "                        self.closed[idx_c] = self.closed[self.num_closed-1]\n",
    "                        self.num_closed -= 1\n",
    "                        idx_c = -1 # // BUGFIX: neighbour is no longer in CLOSED< signal this so that we can re-add it.\n",
    "                \n",
    "                # If neighbour is not in OPEN and neighbour not in CLOSED\n",
    "                if idx_c == -1 and idx_o == -1:\n",
    "                    neighbour.state = to_states[i]\n",
    "                    neighbour.cost = cost\n",
    "                    neighbour.remaining_cost = self.calculate_heuristic(neighbour.state, goal_state)\n",
    "                    neighbour.f = neighbour.cost + neighbour.remaining_cost\n",
    "                    neighbour.action_name = action_names[i]\n",
    "                    neighbour.parent_state = current_node.state\n",
    "                    self.open[self.num_open] = neighbour\n",
    "                    self.num_open+=1\n",
    "                \n",
    "                if self.num_open == MAX_OPEN:\n",
    "                    print(\"Opened set overflow\")\n",
    "                    return -1\n",
    "        return -1\n",
    "    \n",
    "        \n",
    "\n",
    "ap = ActionPlanner()\n",
    "# describe repertoire of actions\n",
    "ap.set_pre_cond(\"scout\", \"armedwithgun\", True)\n",
    "ap.set_post_cond(\"scout\", \"enemyvisible\", True)\n",
    "\n",
    "ap.set_pre_cond(\"approach\", \"enemyvisible\", True)\n",
    "ap.set_post_cond(\"approach\", \"nearenemy\", True)\n",
    "\n",
    "ap.set_pre_cond(\"aim\", \"enemyvisible\", True)\n",
    "ap.set_pre_cond(\"aim\", \"weaponloaded\", True)\n",
    "ap.set_post_cond(\"aim\", \"enemylinedup\", True)\n",
    "\n",
    "ap.set_pre_cond(\"shoot\", \"enemylinedup\", True)\n",
    "ap.set_post_cond(\"shoot\", \"enemyalive\", False)\n",
    "\n",
    "ap.set_pre_cond(\"load\", \"armedwithgun\", True)\n",
    "ap.set_post_cond(\"load\", \"weaponloaded\", True)\n",
    "\n",
    "ap.set_pre_cond(\"detonatebomb\", \"armedwithbomb\", True)\n",
    "ap.set_pre_cond(\"detonatebomb\", \"nearenemy\", True)\n",
    "ap.set_post_cond(\"detonatebomb\", \"alive\", False)\n",
    "ap.set_post_cond(\"detonatebomb\", \"enemyalive\", False)\n",
    "\n",
    "ap.set_pre_cond(\"flee\", \"enemyvisible\", True)\n",
    "ap.set_post_cond(\"flee\", \"nearenemy\", False)\n",
    "\n",
    "print(ap)\n",
    "\n",
    "# describe current world state.\n",
    "fr = State() \n",
    "ap.set_state(fr, \"enemyvisible\", False )\n",
    "ap.set_state(fr, \"armedwithgun\", True )\n",
    "ap.set_state(fr, \"weaponloaded\", False )\n",
    "ap.set_state(fr, \"enemylinedup\", False )\n",
    "ap.set_state(fr, \"enemyalive\", True )\n",
    "ap.set_state(fr, \"armedwithbomb\", True )\n",
    "ap.set_state(fr, \"nearenemy\", False )\n",
    "ap.set_state(fr, \"alive\", True )\n",
    "\n",
    "ap.print_state(fr)\n",
    "print()\n",
    "\n",
    "# describe desired world state.\n",
    "goal = State()\n",
    "ap.set_state(goal, \"enemyalive\", False)\n",
    "print('goal:', bin(goal.state), bin(goal.mask))\n",
    "ap.set_state(goal, \"alive\", True)#// add this to avoid suicide actions in the plan.\n",
    "\n",
    "astar_plan = AStarPlan(ap)\n",
    "plan = astar_plan.plan(fr, goal, 16)\n",
    "\n",
    "print(\"******** PLAN ********\")\n",
    "print(\"plan: \", plan[0])\n",
    "print(\"steps: \", plan[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy GOAP\n",
    "----------\n",
    "State, goal, and action all are a little fuzzy ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "# A state is a graph of the environment\n",
    "\n",
    "# Goal\n",
    "# A desired state. A goal is a constraint between nodes\n",
    "\n",
    "\n",
    "# Action\n",
    "# An atomic affordance that can be performed on a node\n",
    "# These are defined by the designer. We wont want our bot doing\n",
    "# things we have not defined. The complexity of combining these simple\n",
    "# actions is at the heart of this program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
